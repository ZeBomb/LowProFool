{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f88c7cca31f64a69ae62f23cdf908f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37fdebabea334e8bbc2ff0b9ee0b2bc8",
              "IPY_MODEL_222782b3bf4f403cb316fc14e2a3fa98",
              "IPY_MODEL_0a5d831869a3460681e9c97c0a8953d0"
            ],
            "layout": "IPY_MODEL_c34d2786acf449a09bf8ad2323c1ec2b"
          }
        },
        "37fdebabea334e8bbc2ff0b9ee0b2bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0417910abfda4caea4e1c3a5a4e384ae",
            "placeholder": "​",
            "style": "IPY_MODEL_8db21f0ac1b34079a066546b7f8278d8",
            "value": "LowProFool: 100%"
          }
        },
        "222782b3bf4f403cb316fc14e2a3fa98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ffc1ab7595471c8d3b5cbda9766c80",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06245990d1e94ff6868e6f4b0c594a36",
            "value": 150
          }
        },
        "0a5d831869a3460681e9c97c0a8953d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fda2f208c4540e486cf97efa2c8bf12",
            "placeholder": "​",
            "style": "IPY_MODEL_c2faebb0d60d4aa2aa88897770819780",
            "value": " 150/150 [49:02&lt;00:00, 19.40s/it]"
          }
        },
        "c34d2786acf449a09bf8ad2323c1ec2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0417910abfda4caea4e1c3a5a4e384ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db21f0ac1b34079a066546b7f8278d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ffc1ab7595471c8d3b5cbda9766c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06245990d1e94ff6868e6f4b0c594a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fda2f208c4540e486cf97efa2c8bf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2faebb0d60d4aa2aa88897770819780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3b0gLiACyoD"
      },
      "outputs": [],
      "source": [
        "# Misc\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "from torch import tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "e-juQtKQDFVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sklearn\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "iI_-WLaODI9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "# Keras \n",
        "import keras"
      ],
      "metadata": {
        "id": "1PbEJw2rDWAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpers\n",
        "# from Adverse import lowProFool, deepfool\n",
        "# from Metrics import *\n",
        "# Misc\n",
        "import numpy as np\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "# from torch.autograd.gradcheck import zero_gradients\n",
        "def zero_gradients(x):\n",
        "  if x.grad is not None:\n",
        "      x.grad.zero_()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import sklearn\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "def get_metrics(config, list_metrics, n_neighbors=2):\n",
        "    \"\"\"\n",
        "    Generates an adversarial examples x' from an original sample x. Expected to contain\n",
        "            Dataset, MaxIters, Alpha, Lambda, TrainData, TestData, ValidData, Scaler,\n",
        "            FeatureNames, Target, Weights, Bounds, Model\n",
        "    :param config: dictionnary containing the configuration for the experiment\n",
        "    :param list_metrics: dictionnary containing the metrics to be computed. Choose from\n",
        "            from SuccessRate, iter_means, iter_std, normdelta_median, normdelta_mean,\n",
        "            n_std, weighted_median, weighted_mean, w_std, mean_dists_at_org,\n",
        "            median_dists_at_org, mean_dists_at_tgt, mean_dists_at_org_weighted, mdow_std,\n",
        "            median_dists_at_org_weighted, mean_dists_at_tgt_weighted, mdtw_std, prop_same_class_arg_org,\n",
        "            prop_same_class_arg_adv,\n",
        "    :param n_neighbors: number of neighbors to compute the distance to n_neighbors closest neighbors\n",
        "    \"\"\"\n",
        "\n",
        "    metrics_for_conf = []\n",
        "    df_test = config['TestData']\n",
        "    dfs_adv = config['AdvData']\n",
        "    \n",
        "    for method, df_adv in dfs_adv.items():\n",
        "        metrics_for_method = [method]\n",
        "        # Get success rate before removing samples from dataframe\n",
        "        if list_metrics['SuccessRate']:\n",
        "            sr = metric_success_rate_for(df_adv)\n",
        "            metrics_for_method.append(sr)\n",
        "\n",
        "        # Removes samples that did cross frontier\n",
        "        df_adv = remove_non_converted(df_adv)        \n",
        "        df_adv = add_normdelta_to(df_adv, config, df_test)\n",
        "\n",
        "        # Adding proportion of neighbors from diff classes\n",
        "        df_adv, df_adv_weighted = add_maj_neighbors(df_adv, df_test, config, n_neighbors=n_neighbors)            \n",
        "\n",
        "        # Mean, std, number of iterations\n",
        "        if list_metrics['iter_means']:\n",
        "            means_iters, stds_iters = mean_norm_for_col(df_adv, col='iters')\n",
        "            metrics_for_method.append(means_iters)\n",
        "            if list_metrics['iter_std']:\n",
        "                metrics_for_method.append(stds_iters)\n",
        "\n",
        "        # Median, norm of perturbation\n",
        "        if list_metrics['normdelta_median']:\n",
        "            median = median_norm_for_col(df_adv, col='normdelta')\n",
        "            metrics_for_method.append(median)\n",
        "\n",
        "        # Mean, std, norm of perturbation\n",
        "        if list_metrics['normdelta_mean']:\n",
        "            means, stds = mean_norm_for_col(df_adv, col='normdelta')\n",
        "            metrics_for_method.append(means)\n",
        "            if list_metrics['n_std']:\n",
        "                metrics_for_method.append(stds)\n",
        "\n",
        "        # Median, norm of perturbation, weighted\n",
        "        if list_metrics['weighted_median']:\n",
        "            median_w = median_norm_for_col(df_adv, col='normdelta_weighted')\n",
        "            metrics_for_method.append(median_w)\n",
        "\n",
        "        # Mean, std, norm of perturbation, weighted\n",
        "        if list_metrics['weighted_mean']:\n",
        "            means_w, stds_w = mean_norm_for_col(df_adv, col='normdelta_weighted')\n",
        "            metrics_for_method.append(means_w)\n",
        "            if list_metrics['w_std']:\n",
        "                metrics_for_method.append(stds_w) \n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['mean_dists_at_org']:\n",
        "            mean, std = mean_norm_for_col(df_adv, col='mean_dists_at_org')\n",
        "            metrics_for_method.append(mean)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['median_dists_at_org']:\n",
        "            med = median_norm_for_col(df_adv, col='mean_dists_at_org')\n",
        "            metrics_for_method.append(med)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['mean_dists_at_tgt']:\n",
        "            mean, std = mean_norm_for_col(df_adv, col='mean_dists_at_tgt')\n",
        "            metrics_for_method.append(mean)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['mean_dists_at_org_weighted']:\n",
        "            mean, std = mean_norm_for_col(df_adv_weighted, col='mean_dists_at_org')\n",
        "            metrics_for_method.append(mean)\n",
        "            if list_metrics['mdow_std']:\n",
        "                metrics_for_method.append(std)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['median_dists_at_org_weighted']:\n",
        "            median = median_norm_for_col(df_adv_weighted, col='mean_dists_at_org')\n",
        "            metrics_for_method.append(median)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['mean_dists_at_tgt_weighted']:\n",
        "            mean, std = mean_norm_for_col(df_adv_weighted, col='mean_dists_at_tgt')\n",
        "            metrics_for_method.append(mean)\n",
        "            if list_metrics['mdtw_std']:\n",
        "                metrics_for_method.append(std)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['prop_same_class_arg_org']:\n",
        "            mean, std = mean_norm_for_col(df_adv, col='prop_same_class_arg_org')\n",
        "            metrics_for_method.append(mean)\n",
        "\n",
        "        # Mean, std, number of neighbors of a particular class at perturbed sample\n",
        "        if list_metrics['prop_same_class_arg_adv']:\n",
        "            mean, std = mean_norm_for_col(df_adv, col='prop_same_class_arg_adv')\n",
        "            metrics_for_method.append(mean)\n",
        "            \n",
        "        metrics_for_conf.append(metrics_for_method)\n",
        "    return metrics_for_conf\n",
        "  \n",
        "def metric_success_rate_for(df):\n",
        "    return len(df[df['orig_pred'] != df['adv_pred']]) / df.shape[0]\n",
        "\n",
        "def remove_non_converted(df):\n",
        "    df_return = df.copy()\n",
        "    return df[df['orig_pred'] != df['adv_pred']]\n",
        "\n",
        "def mean_norm_for_col(df, col):\n",
        "    tmp = df[col]    \n",
        "    mean, std = np.mean(tmp), np.std(tmp)\n",
        "    return (mean, std)\n",
        "\n",
        "def median_norm_for_col(df, col):\n",
        "    tmp = df[col]    \n",
        "    median = np.median(tmp)\n",
        "    return median\n",
        "\n",
        "def add_normdelta_to(df_adv, conf, df):\n",
        "    # Drop columns if already there\n",
        "    df_return = df_adv.copy()\n",
        "    if 'normdelta' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='normdelta')\n",
        "    if 'normdelta_weighted' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='normdelta_weighted')\n",
        "        \n",
        "    feature_names = conf['FeatureNames']\n",
        "    weights = conf['Weights']\n",
        "\n",
        "    norms = []\n",
        "    norms_weighted = []\n",
        "    \n",
        "    # Iterate over all rows\n",
        "    for index, row in df_return.iterrows():\n",
        "        orig = df.loc[index][feature_names].values\n",
        "        adv = row[feature_names].values \n",
        "        \n",
        "        # Compute deltas\n",
        "        delta = np.abs(orig-adv)\n",
        "        assert(len(delta) == len(weights))\n",
        "        \n",
        "        # Norms delta\n",
        "        norms.append(np.linalg.norm(delta))\n",
        "        \n",
        "        # Norms delta weighted\n",
        "        norms_weighted.append(np.linalg.norm(delta * weights))\n",
        "\n",
        "    df_return.insert(0, 'normdelta', norms)\n",
        "    df_return.insert(0, 'normdelta_weighted', norms_weighted)\n",
        "    \n",
        "    return df_return\n",
        "\n",
        "\n",
        "def get_majority_neighbors(df_adv, df_orig, conf, knn, n_neighbors):\n",
        "    \n",
        "    # orig, adv\n",
        "    mean_dists = [[], []]\n",
        "    prop_same_class = [[], []]\n",
        "    \n",
        "    feature_names = conf['FeatureNames']\n",
        "    target = conf['Target']    \n",
        "    \n",
        "    # For each sample\n",
        "    for index, row in df_adv.iterrows():\n",
        "        \n",
        "        orig = df_orig.loc[index][feature_names].values\n",
        "        adv = row[feature_names].values\n",
        "        \n",
        "        preds = [row['orig_pred'], row['adv_pred']]\n",
        "        samples = [orig, adv]\n",
        "        \n",
        "        for i in range(len(preds)):\n",
        "            \n",
        "            sample = samples[i]\n",
        "            pred = preds[i]\n",
        "            \n",
        "            distance, neighbors_idxs = knn.kneighbors([sample], n_neighbors)\n",
        "            neighbors_samples = df_orig.iloc[neighbors_idxs[0]]\n",
        "            \n",
        "           \n",
        "            distance = [distance[0][1:]]\n",
        "            neighbors_idxs = [neighbors_idxs[0][1:]]\n",
        "            \n",
        "\n",
        "            # Distance to closest neighbors\n",
        "            if len(distance[0]) > 0 :\n",
        "                dst_mean = np.mean(distance[0])\n",
        "            else:\n",
        "                print('Error, no neighbor found')\n",
        "            mean_dists[i].append(dst_mean)\n",
        "            \n",
        "            neighbors_pts_target = np.array(neighbors_samples[target]).astype(int)\n",
        "            prop = list(neighbors_pts_target).count(pred)\n",
        "            prop_same_class[i].append(float(prop)/float(n_neighbors))\n",
        "                        \n",
        "    return mean_dists, prop_same_class\n",
        "\n",
        "def add_maj_neighbors_to(df_adv, df_orig, conf, knn, n_neighbors):\n",
        "    df_return = df_adv.copy()\n",
        "    \n",
        "    if 'mean_dists_at_org' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='mean_dists_at_org')\n",
        "    if 'mean_dists_at_tgt' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='mean_dists_at_tgt')\n",
        "    if 'prop_same_class_arg_org' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='prop_same_class_arg_org')\n",
        "    if 'prop_same_class_arg_adv' in df_return.columns:\n",
        "        df_return = df_return.drop(columns='prop_same_class_arg_adv')\n",
        "        \n",
        "    mean_dists, prop_same_class = get_majority_neighbors(df_adv, df_orig, conf, knn, n_neighbors)\n",
        "    \n",
        "    df_return.insert(0, 'mean_dists_at_org', mean_dists[0])\n",
        "    df_return.insert(0, 'mean_dists_at_tgt', mean_dists[1])\n",
        "\n",
        "    df_return.insert(0, 'prop_same_class_arg_org', prop_same_class[0])\n",
        "    df_return.insert(0, 'prop_same_class_arg_adv', prop_same_class[1])\n",
        "    \n",
        "    return df_return\n",
        "\n",
        "def scale_data(conf, df_orig):\n",
        "    print('Before')\n",
        "    print(df.describe(include='all'))\n",
        "    print(weights)\n",
        "    for col, weight in zip(list(df.columns), weights):\n",
        "        df[col] = df[col].apply(lambda x: x * weight)\n",
        "        \n",
        "    bounds = [[bounds[i][x] * weight for x, weight in enumerate(weights)] for i in range(len(bounds))]\n",
        "    print(df.describe(include='all'))\n",
        "    return df, bounds\n",
        "\n",
        "def weighted_distance(x, y, w):\n",
        "    sum_ = 0\n",
        "    assert(len(x) == len(y) == len(w))\n",
        "    for i in range(len(x)):\n",
        "        sum_ += (w[i] * (y[i] - x[i])) ** 2\n",
        "    sum_ = np.sqrt(sum_)\n",
        "    return sum_\n",
        "\n",
        "def add_maj_neighbors(df_adv, df_orig, conf, n_neighbors):\n",
        "    # Otherwise we have issues because the KNN returns indexes in len(df) and not based on the real indexes on the samples\n",
        "    df_adv = df_adv.reset_index().drop(columns=['index'])\n",
        "    df_orig = df_orig.reset_index().drop(columns=['index'])\n",
        "    weights = conf['Weights']\n",
        "\n",
        "    assert(weights[0] > 0)\n",
        "\n",
        "    feature_names = conf['FeatureNames']\n",
        "    target = conf['Target']\n",
        "        \n",
        "        \n",
        "    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='l2')\n",
        "    knn.fit(df_orig[feature_names], df_orig[target])\n",
        "    \n",
        "    knn_weighted = NearestNeighbors(n_neighbors=n_neighbors, metric=weighted_distance, metric_params={'w' : weights})\n",
        "    knn_weighted.fit(df_orig[feature_names], df_orig[target])\n",
        "\n",
        "    \n",
        "    df_adv_return = add_maj_neighbors_to(df_adv, df_orig, conf, knn, n_neighbors)\n",
        "    df_adv_weighted = add_maj_neighbors_to(df_adv, df_orig, conf, knn_weighted, n_neighbors)\n",
        "    \n",
        "    return df_adv_return, df_adv_weighted\n"
      ],
      "metadata": {
        "id": "TvoM7ATmDYOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misc\n",
        "import numpy as np\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "# from torch.autograd.gradcheck import zero_gradients\n",
        "\n",
        "# Clipping function\n",
        "def clip(current, low_bound, up_bound):\n",
        "    assert(len(current) == len(up_bound) and len(low_bound) == len(up_bound))\n",
        "    low_bound = torch.FloatTensor(low_bound)\n",
        "    up_bound = torch.FloatTensor(up_bound)\n",
        "    clipped = torch.max(torch.min(current, up_bound), low_bound)\n",
        "    return clipped\n",
        "\n",
        "\n",
        "def lowProFool(x, model, weights, bounds, maxiters, alpha, lambda_, cat_indices=[]):\n",
        "    \"\"\"\n",
        "    Generates an adversarial examples x' from an original sample x\n",
        "\n",
        "    :param x: tabular sample\n",
        "    :param model: neural network\n",
        "    :param weights: feature importance vector associated with the dataset at hand\n",
        "    :param bounds: bounds of the datasets with respect to each feature\n",
        "    :param maxiters: maximum number of iterations ran to generate the adversarial examples\n",
        "    :param alpha: scaling factor used to control the growth of the perturbation\n",
        "    :param lambda_: trade off factor between fooling the classifier and generating imperceptible adversarial example\n",
        "    :return: original label prediction, final label prediction, adversarial examples x', iteration at which the class changed\n",
        "    \"\"\"\n",
        "\n",
        "    r = Variable(torch.FloatTensor(1e-4 * np.ones(x.numpy().shape)), requires_grad=True) \n",
        "    v = torch.FloatTensor(np.array(weights))\n",
        "    \n",
        "    output = model.forward(x + r)\n",
        "    orig_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "    target_pred = np.abs(1 - orig_pred)\n",
        "    \n",
        "    target = [0., 1.] if target_pred == 1 else [1., 0.]\n",
        "    target = Variable(torch.tensor(target, requires_grad=False)) \n",
        "    \n",
        "    lambda_ = torch.tensor([lambda_])\n",
        "    \n",
        "    bce = nn.BCELoss()\n",
        "    l1 = lambda v, r: torch.sum(torch.abs(v * r)) #L1 norm\n",
        "    l2 = lambda v, r: torch.sqrt(torch.sum(torch.mul(v * r,v * r))) #L2 norm\n",
        "    \n",
        "    best_norm_weighted = np.inf\n",
        "    best_pert_x = x\n",
        "    \n",
        "    loop_i, loop_change_class = 0, 0\n",
        "    while loop_i < maxiters:\n",
        "            \n",
        "        zero_gradients(r)\n",
        "\n",
        "        # Computing loss \n",
        "        loss_1 = bce(output, target)\n",
        "        loss_2 = l2(v, r)\n",
        "        loss = (loss_1 + lambda_ * loss_2)\n",
        "\n",
        "        # Get the gradient\n",
        "        loss.backward(retain_graph=True)\n",
        "        grad_r = r.grad.data.cpu().numpy().copy()\n",
        "        \n",
        "        # Guide perturbation to the negative of the gradient\n",
        "        ri = - grad_r\n",
        "    \n",
        "        # limit huge step\n",
        "        ri *= alpha\n",
        "\n",
        "        # Adds new perturbation to total perturbation\n",
        "        r = r.clone().detach().cpu().numpy() + ri\n",
        "        \n",
        "        # For later computation\n",
        "        r_norm_weighted = np.sum(np.abs(r * weights))\n",
        "        \n",
        "        # Ready to feed the model\n",
        "        r = Variable(torch.FloatTensor(r), requires_grad=True) \n",
        "        \n",
        "        # Compute adversarial example\n",
        "        xprime = x + r\n",
        "        \n",
        "        # Clip to stay in legitimate bounds\n",
        "        xprime = clip(xprime, bounds[0], bounds[1])\n",
        "        \n",
        "        # Classify adversarial example\n",
        "        output = model.forward(xprime)\n",
        "        output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "        \n",
        "        # Keep the best adverse at each iterations\n",
        "        if output_pred != orig_pred and r_norm_weighted < best_norm_weighted:\n",
        "            best_norm_weighted = r_norm_weighted\n",
        "            best_pert_x = xprime\n",
        "\n",
        "        if output_pred == orig_pred:\n",
        "            loop_change_class += 1\n",
        "            \n",
        "        loop_i += 1 \n",
        "        \n",
        "    # Clip at the end no matter what\n",
        "    best_pert_x = clip(best_pert_x, bounds[0], bounds[1])\n",
        "    output = model.forward(best_pert_x)\n",
        "    output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "\n",
        "    return orig_pred, output_pred, best_pert_x.clone().detach().cpu().numpy(), loop_change_class \n",
        "\n",
        "# Forked from https://github.com/LTS4/DeepFool\n",
        "def deepfool(x_old, net, maxiters, alpha, bounds, weights=[], overshoot=0.002):\n",
        "    \"\"\"\n",
        "    :param image: tabular sample\n",
        "    :param net: network \n",
        "    :param maxiters: maximum number of iterations ran to generate the adversarial examples\n",
        "    :param alpha: scaling factor used to control the growth of the perturbation\n",
        "    :param bounds: bounds of the datasets with respect to each feature\n",
        "    :param weights: feature importance vector associated with the dataset at hand\n",
        "    :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
        "    :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
        "    \"\"\"\n",
        "    \n",
        "    input_shape = x_old.numpy().shape\n",
        "    x = x_old.clone()\n",
        "    x = Variable(x, requires_grad=True)\n",
        "    \n",
        "    output = net.forward(x)\n",
        "    orig_pred = output.max(0, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    origin = Variable(torch.tensor([orig_pred], requires_grad=False))\n",
        "\n",
        "    I = []\n",
        "    if orig_pred == 0:\n",
        "        I = [0, 1]\n",
        "    else:\n",
        "        I = [1, 0]\n",
        "        \n",
        "    w = np.zeros(input_shape)\n",
        "    r_tot = np.zeros(input_shape)\n",
        "    \n",
        "    k_i = origin\n",
        " \n",
        "    loop_i = 0\n",
        "    while torch.eq(k_i, origin) and loop_i < maxiters:\n",
        "                \n",
        "        # Origin class\n",
        "        output[I[0]].backward(retain_graph=True)\n",
        "        grad_orig = x.grad.data.numpy().copy()\n",
        "        \n",
        "        # Target class\n",
        "        zero_gradients(x)\n",
        "        output[I[1]].backward(retain_graph=True)\n",
        "        cur_grad = x.grad.data.numpy().copy()\n",
        "            \n",
        "        # set new w and new f\n",
        "        w = cur_grad - grad_orig\n",
        "        f = (output[I[1]] - output[I[0]]).data.numpy()\n",
        "\n",
        "        pert = abs(f)/np.linalg.norm(w.flatten())\n",
        "    \n",
        "        # compute r_i and r_tot\n",
        "        # Added 1e-4 for numerical stability\n",
        "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)   \n",
        "        \n",
        "        if len(weights) > 0:\n",
        "            r_i /= np.array(weights)\n",
        "\n",
        "        # limit huge step\n",
        "        r_i = alpha * r_i / np.linalg.norm(r_i) \n",
        "            \n",
        "        r_tot = np.float32(r_tot + r_i)\n",
        "        \n",
        "        \n",
        "        pert_x = x_old + (1 + overshoot) * torch.from_numpy(r_tot)\n",
        "\n",
        "        if len(bounds) > 0:\n",
        "            pert_x = clip(pert_x, bounds[0], bounds[1])\n",
        "                \n",
        "        x = Variable(pert_x, requires_grad=True)\n",
        " \n",
        "        output = net.forward(x)\n",
        "        \n",
        "        k_i = torch.tensor(np.argmax(output.data.cpu().numpy().flatten()))\n",
        "                    \n",
        "        loop_i += 1\n",
        "\n",
        "    r_tot = (1+overshoot)*r_tot    \n",
        "    pert_x = clip(pert_x, bounds[0], bounds[1])\n",
        "\n",
        "    return orig_pred, k_i, pert_x.cpu(), loop_i"
      ],
      "metadata": {
        "id": "tos17z1PE4KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misc\n",
        "import numpy as np\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "# from torch.autograd.gradcheck import zero_gradients\n",
        "\n",
        "# Clipping function\n",
        "def clip(current, low_bound, up_bound):\n",
        "    assert(len(current) == len(up_bound) and len(low_bound) == len(up_bound))\n",
        "    low_bound = torch.FloatTensor(low_bound)\n",
        "    up_bound = torch.FloatTensor(up_bound)\n",
        "    clipped = torch.max(torch.min(current, up_bound), low_bound)\n",
        "    return clipped\n",
        "\n",
        "\n",
        "def lowProFool(x, model, weights, bounds, maxiters, alpha, lambda_, cat_indices=[]):\n",
        "    \"\"\"\n",
        "    Generates an adversarial examples x' from an original sample x\n",
        "\n",
        "    :param x: tabular sample\n",
        "    :param model: neural network\n",
        "    :param weights: feature importance vector associated with the dataset at hand\n",
        "    :param bounds: bounds of the datasets with respect to each feature\n",
        "    :param maxiters: maximum number of iterations ran to generate the adversarial examples\n",
        "    :param alpha: scaling factor used to control the growth of the perturbation\n",
        "    :param lambda_: trade off factor between fooling the classifier and generating imperceptible adversarial example\n",
        "    :return: original label prediction, final label prediction, adversarial examples x', iteration at which the class changed\n",
        "    \"\"\"\n",
        "\n",
        "    r = Variable(torch.FloatTensor(1e-4 * np.ones(x.numpy().shape)), requires_grad=True) \n",
        "    v = torch.FloatTensor(np.array(weights))\n",
        "    \n",
        "    output = model.forward(x + r)\n",
        "    orig_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "    target_pred = np.abs(1 - orig_pred)\n",
        "    \n",
        "    target = [0., 1.] if target_pred == 1 else [1., 0.]\n",
        "    target = Variable(torch.tensor(target, requires_grad=False)) \n",
        "    \n",
        "    lambda_ = torch.tensor([lambda_])\n",
        "    \n",
        "    bce = nn.BCELoss()\n",
        "    l1 = lambda v, r: torch.sum(torch.abs(v * r)) #L1 norm\n",
        "    l2 = lambda v, r: torch.sqrt(torch.sum(torch.mul(v * r,v * r))) #L2 norm\n",
        "    \n",
        "    best_norm_weighted = np.inf\n",
        "    best_pert_x = x\n",
        "    \n",
        "    loop_i, loop_change_class = 0, 0\n",
        "    while loop_i < maxiters:\n",
        "            \n",
        "        zero_gradients(r)\n",
        "\n",
        "        # Computing loss \n",
        "        loss_1 = bce(output, target)\n",
        "        loss_2 = l2(v, r)\n",
        "        loss = (loss_1 + lambda_ * loss_2)\n",
        "\n",
        "        # Get the gradient\n",
        "        loss.backward(retain_graph=True)\n",
        "        grad_r = r.grad.data.cpu().numpy().copy()\n",
        "        \n",
        "        # Guide perturbation to the negative of the gradient\n",
        "        ri = - grad_r\n",
        "    \n",
        "        # limit huge step\n",
        "        ri *= alpha\n",
        "\n",
        "        # Adds new perturbation to total perturbation\n",
        "        r = r.clone().detach().cpu().numpy() + ri\n",
        "        \n",
        "        # For later computation\n",
        "        r_norm_weighted = np.sum(np.abs(r * weights))\n",
        "        \n",
        "        # Ready to feed the model\n",
        "        r = Variable(torch.FloatTensor(r), requires_grad=True) \n",
        "        \n",
        "        # Compute adversarial example\n",
        "        xprime = x + r\n",
        "        \n",
        "        # Clip to stay in legitimate bounds\n",
        "        xprime = clip(xprime, bounds[0], bounds[1])\n",
        "        \n",
        "        # Classify adversarial example\n",
        "        output = model.forward(xprime)\n",
        "        output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "        \n",
        "        # Keep the best adverse at each iterations\n",
        "        if output_pred != orig_pred and r_norm_weighted < best_norm_weighted:\n",
        "            best_norm_weighted = r_norm_weighted\n",
        "            best_pert_x = xprime\n",
        "\n",
        "        if output_pred == orig_pred:\n",
        "            loop_change_class += 1\n",
        "            \n",
        "        loop_i += 1 \n",
        "        \n",
        "    # Clip at the end no matter what\n",
        "    best_pert_x = clip(best_pert_x, bounds[0], bounds[1])\n",
        "    output = model.forward(best_pert_x)\n",
        "    output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "\n",
        "    return orig_pred, output_pred, best_pert_x.clone().detach().cpu().numpy(), loop_change_class \n",
        "\n",
        "# Forked from https://github.com/LTS4/DeepFool\n",
        "def deepfool(x_old, net, maxiters, alpha, bounds, weights=[], overshoot=0.002):\n",
        "    \"\"\"\n",
        "    :param image: tabular sample\n",
        "    :param net: network \n",
        "    :param maxiters: maximum number of iterations ran to generate the adversarial examples\n",
        "    :param alpha: scaling factor used to control the growth of the perturbation\n",
        "    :param bounds: bounds of the datasets with respect to each feature\n",
        "    :param weights: feature importance vector associated with the dataset at hand\n",
        "    :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
        "    :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
        "    \"\"\"\n",
        "    \n",
        "    input_shape = x_old.numpy().shape\n",
        "    x = x_old.clone()\n",
        "    x = Variable(x, requires_grad=True)\n",
        "    \n",
        "    output = net.forward(x)\n",
        "    orig_pred = output.max(0, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "    origin = Variable(torch.tensor([orig_pred], requires_grad=False))\n",
        "\n",
        "    I = []\n",
        "    if orig_pred == 0:\n",
        "        I = [0, 1]\n",
        "    else:\n",
        "        I = [1, 0]\n",
        "        \n",
        "    w = np.zeros(input_shape)\n",
        "    r_tot = np.zeros(input_shape)\n",
        "    \n",
        "    k_i = origin\n",
        " \n",
        "    loop_i = 0\n",
        "    while torch.eq(k_i, origin) and loop_i < maxiters:\n",
        "                \n",
        "        # Origin class\n",
        "        output[I[0]].backward(retain_graph=True)\n",
        "        grad_orig = x.grad.data.numpy().copy()\n",
        "        \n",
        "        # Target class\n",
        "        zero_gradients(x)\n",
        "        output[I[1]].backward(retain_graph=True)\n",
        "        cur_grad = x.grad.data.numpy().copy()\n",
        "            \n",
        "        # set new w and new f\n",
        "        w = cur_grad - grad_orig\n",
        "        f = (output[I[1]] - output[I[0]]).data.numpy()\n",
        "\n",
        "        pert = abs(f)/np.linalg.norm(w.flatten())\n",
        "    \n",
        "        # compute r_i and r_tot\n",
        "        # Added 1e-4 for numerical stability\n",
        "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)   \n",
        "        \n",
        "        if len(weights) > 0:\n",
        "            r_i /= np.array(weights)\n",
        "\n",
        "        # limit huge step\n",
        "        r_i = alpha * r_i / np.linalg.norm(r_i) \n",
        "            \n",
        "        r_tot = np.float32(r_tot + r_i)\n",
        "        \n",
        "        \n",
        "        pert_x = x_old + (1 + overshoot) * torch.from_numpy(r_tot)\n",
        "\n",
        "        if len(bounds) > 0:\n",
        "            pert_x = clip(pert_x, bounds[0], bounds[1])\n",
        "                \n",
        "        x = Variable(pert_x, requires_grad=True)\n",
        " \n",
        "        output = net.forward(x)\n",
        "        \n",
        "        k_i = torch.tensor(np.argmax(output.data.cpu().numpy().flatten()))\n",
        "                    \n",
        "        loop_i += 1\n",
        "\n",
        "    r_tot = (1+overshoot)*r_tot    \n",
        "    pert_x = clip(pert_x, bounds[0], bounds[1])\n",
        "\n",
        "    return orig_pred, k_i, pert_x.cpu(), loop_i"
      ],
      "metadata": {
        "id": "RGtNG1HiDaka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 0\n",
        "DATASET = 'Transactions'"
      ],
      "metadata": {
        "id": "6m32Tb_YDc0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_df(dataset):\n",
        "#     assert(dataset == 'credit-g')\n",
        "    \n",
        "#     dataset = fetch_openml(dataset)\n",
        "#     target = 'target'\n",
        "#     df = pd.DataFrame(data= np.c_[dataset['data'], dataset[target]], columns= dataset['feature_names'] + [target])  \n",
        "\n",
        "#     # Renaming target for training later\n",
        "#     df[target] = df[target].apply(lambda x: 0.0 if x == 'bad' or x == 0.0 else 1.0)\n",
        "\n",
        "#     # Subsetting features to keep only continuous, discrete and ordered categorical\n",
        "#     feature_names = ['checking_status', 'duration', 'credit_amount',\n",
        "#                  'savings_status','employment','installment_commitment',\n",
        "#                  'residence_since','age','existing_credits','num_dependents',\n",
        "#                  'own_telephone','foreign_worker']\n",
        "\n",
        "#     df = df[feature_names + [target]]\n",
        "\n",
        "#     # Casting to float for later purpose\n",
        "#     df = df.astype(float)\n",
        "#     return df, target, feature_names\n",
        "#def get_df(dataset):\n",
        " #   assert(dataset == 'credit-g')\n",
        "    \n",
        "  #  dataset = fetch_openml(dataset)\n",
        "   # target = 'target'\n",
        "    #df = pd.DataFrame(data= np.c_[dataset['data'], dataset[target]], columns= dataset['feature_names'] + [target])  \n",
        "\n",
        "    # Renaming target for training later\n",
        "    #df[target] = df[target].apply(lambda x: 0.0 if x == 'bad' or x == 0.0 else 1.0)\n",
        "\n",
        "    # Subsetting features to keep only continuous, discrete and ordered categorical\n",
        "    #feature_names = ['checking_status', 'duration', 'credit_amount',\n",
        "     #            'savings_status','employment','installment_commitment',\n",
        "      #           'residence_since','age','existing_credits','num_dependents',\n",
        "       #          'own_telephone','foreign_worker']\n",
        "\n",
        "    #df = df[feature_names + [target]]\n",
        "    #df['checking_status']=df['checking_status'].map({'<0':0, '0<=X<200':2, 'no checking':1, '>=200':3})\n",
        "    #df['savings_status']=df['savings_status'].map({'no known savings':0, '<100':1, '500<=X<1000':3, '>=1000':4, '100<=X<500':2})\n",
        "    #df['employment']=df['employment'].map({'>=7':4, '1<=X<4':2, '4<=X<7':3, 'unemployed':0, '<1':1})\n",
        "    #df['own_telephone']=df['own_telephone'].map({'yes':1, 'none':0})\n",
        "    #df['foreign_worker']=df['foreign_worker'].map({'yes':1, 'no':0})\n",
        "\n",
        "\n",
        "    # Casting to float for later purpose\n",
        "    #print(df.head())\n",
        "    #df = df['checking_status'].astype(float)\n",
        "    #df = df.astype(float)\n",
        "   # return df, target, feature_names\n",
        "\n",
        "\n",
        "def get_df2(ds):\n",
        "  df_new = pd.read_csv(\"/content/drive/MyDrive/transactions.csv\")\n",
        "  df_new.drop(['merchantCity','merchantState','merchantZip','echoBuffer','posOnPremises','recurringAuthInd', 'Unnamed: 0'],axis=1,inplace=True)\n",
        "  df_new.drop(['accountNumber','customerId','merchantName'],axis=1,inplace=True)\n",
        "  df_new['transactionDateTime'] = pd.to_datetime(df_new['transactionDateTime'])\n",
        "\n",
        "  df_new['transactionDateTime_month'] = df_new['transactionDateTime'].dt.month\n",
        "  df_new['transactionDateTime_hour'] = df_new['transactionDateTime'].dt.hour\n",
        "\n",
        "  df_new.drop('transactionDateTime',axis = 1,inplace = True)\n",
        "  df_new.drop('currentExpDate',axis = 1,inplace = True)\n",
        "  df_new.drop('accountOpenDate',axis = 1,inplace = True)\n",
        "  df_new.drop('dateOfLastAddressChange',axis = 1,inplace = True)\n",
        "\n",
        "\n",
        "  df_new['availableMoney'] = df_new['availableMoney']/df_new['creditLimit']\n",
        "  df_new['transactionAmount']=df_new['transactionAmount']/df_new['creditLimit']\n",
        "  df_new['currentBalance']=df_new['currentBalance']/df_new['creditLimit']\n",
        "  df_new['isCVVcorrect']=(df_new['cardCVV']==df_new['enteredCVV'])\n",
        "  df_new['isSameCountry']=(df_new['acqCountry']==df_new['merchantCountryCode'])\n",
        "\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  le = LabelEncoder()\n",
        "  var = ['posEntryMode','posConditionCode','merchantCategoryCode','transactionType','cardPresent','expirationDateKeyInMatch','isFraud']\n",
        "  for i in var:\n",
        "      df_new[i] = le.fit_transform(df_new[i])\n",
        "\n",
        "  df_new.drop(['enteredCVV','cardCVV','merchantCountryCode','acqCountry','cardLast4Digits','creditLimit'],axis=1,inplace=True)\n",
        "  X=df_new['isFraud'].copy()\n",
        "  df_new.drop(['isFraud'],inplace=True,axis=1)\n",
        "  df_new['isFraud'] = X\n",
        "\n",
        "  feature_names = ['availableMoney', 'transactionAmount', 'posEntryMode',\n",
        "       'posConditionCode', 'merchantCategoryCode', 'transactionType',\n",
        "       'currentBalance', 'cardPresent', 'expirationDateKeyInMatch',\n",
        "       'transactionDateTime_month','transactionDateTime_hour', 'isCVVcorrect', 'isSameCountry']\n",
        "  target = 'isFraud'\n",
        "  \n",
        "  return df_new, target, feature_names\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "TFe70uq-De3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df, target, feature_names, bounds):\n",
        "    df_return = df.copy()\n",
        "    # Makes sure target does not need scaling\n",
        "    targets = np.unique(df[target].values)\n",
        "    assert(len(targets == 2) and 0. in targets and 1. in targets)\n",
        "    \n",
        "    scaler = MinMaxScaler()\n",
        "    X = df_return[feature_names]\n",
        "    scaler.fit(X)    \n",
        "    df_return[feature_names] = scaler.transform(X)\n",
        "    \n",
        "    lower_bounds = scaler.transform([bounds[0]])\n",
        "    upper_bounds = scaler.transform([bounds[1]])\n",
        "\n",
        "    return scaler, df_return, (lower_bounds[0], upper_bounds[0])\n",
        "\n",
        "def get_weights(df, target, show_heatmap=False):\n",
        "    def heatmap(cor):\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
        "        plt.show()\n",
        "\n",
        "    cor = df.corr()\n",
        "    cor_target = abs(cor[target])\n",
        "\n",
        "    weights = cor_target[:-1] #removing target WARNING ASSUMES TARGET IS LAST\n",
        "    weights = weights / np.linalg.norm(weights)\n",
        "\n",
        "    if show_heatmap:\n",
        "        heatmap(cor)\n",
        "            \n",
        "    return weights.values\n",
        "\n",
        "def balance_df(df):\n",
        "    len_df_0, len_df_1 = len(df[df[target] == 0.]), len(df[df[target] == 1.])\n",
        "    df_0 = df[df[target] == 0.].sample(min(len_df_0, len_df_1), random_state=SEED)\n",
        "    df_1 = df[df[target] == 1.].sample(min(len_df_0, len_df_1), random_state=SEED)\n",
        "    df = pd.concat((df_0, df_1))\n",
        "    return df\n",
        "\n",
        "def get_bounds():\n",
        "    low_bounds = df_orig.min().values\n",
        "    up_bounds = df_orig.max().values\n",
        "    \n",
        "    #removing target WARNING ASSUMES TARGET IS LAST\n",
        "    low_bounds = low_bounds[:-1]\n",
        "    up_bounds = up_bounds[:-1]\n",
        "    \n",
        "    return [low_bounds, up_bounds]\n",
        "\n",
        "def split_train_test_valid(val_size=50,test_size=300):\n",
        "    # Train test splits\n",
        "    print(df.shape)\n",
        "    df_train, df_test = train_test_split(df, test_size=test_size, shuffle=True, random_state=SEED)\n",
        "    df_test, df_valid = train_test_split(df_test, test_size=val_size, shuffle=True, random_state=SEED)\n",
        "    \n",
        "    return df_train, df_test, df_valid"
      ],
      "metadata": {
        "id": "nTX_EKpWDf1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(conf, load=False):\n",
        "    assert(conf['Dataset'] == 'credit-g')\n",
        "    \n",
        "    class Linear(nn.Module):\n",
        "        def __init__(self, D_in, H, D_out):\n",
        "            super(Linear, self).__init__()\n",
        "            self.linear1 = torch.nn.Linear(D_in, H)\n",
        "            self.linear2 = torch.nn.Linear(H, H)\n",
        "            self.linear3 = torch.nn.Linear(H, D_out)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.softmax = torch.nn.Softmax(dim=0)\n",
        "\n",
        "        def forward(self, x):\n",
        "            h1 = self.relu(self.linear1(x))\n",
        "            h2 = self.relu(self.linear2(h1))\n",
        "            h3 = self.relu(self.linear2(h2))\n",
        "            h4 = self.relu(self.linear2(h3))\n",
        "            h5 = self.relu(self.linear2(h4))\n",
        "            h6 = self.relu(self.linear2(h5))\n",
        "            a3 = self.linear3(h6)\n",
        "            y = self.softmax(a3)\n",
        "            return y\n",
        "\n",
        "    def train(model, criterion, optimizer, X, y, N, n_classes):\n",
        "        model.train()\n",
        "\n",
        "        current_loss = 0\n",
        "        current_correct = 0\n",
        "\n",
        "\n",
        "        # Training in batches\n",
        "        for ind in range(0, X.size(0), N):\n",
        "            indices = range(ind, min(ind + N, X.size(0)) - 1) \n",
        "            inputs, labels = X[indices], y[indices]\n",
        "            inputs = Variable(inputs, requires_grad=True)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(inputs)\n",
        "            _, indices = torch.max(output, 1) # argmax of output [[0.61, 0.12]] -> [0]\n",
        "            # [[0, 1, 1, 0, 1, 0, 0]] -> [[1, 0], [0, 1], [0, 1], [1, 0], [0, 1], [1, 0], [1, 0]]\n",
        "            preds = torch.tensor(keras.utils.to_categorical(indices, num_classes=n_classes))\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            current_loss += loss.item()\n",
        "            current_correct += (preds.int() == labels.int()).sum() /n_classes\n",
        "\n",
        "\n",
        "        current_loss = current_loss / X.size(0)\n",
        "        current_correct = current_correct.double() / X.size(0)    \n",
        "\n",
        "        return preds, current_loss, current_correct.item()\n",
        "    \n",
        "    df = conf['TrainData']\n",
        "    target = conf['Target']\n",
        "    feature_names = conf['FeatureNames']\n",
        "                        \n",
        "    n_classes = len(np.unique(df[target]))\n",
        "    X_train = torch.FloatTensor(df[feature_names].values)\n",
        "    y_train = keras.utils.to_categorical(df[target], n_classes)\n",
        "    y_train = torch.FloatTensor(y_train)\n",
        "\n",
        "    D_in = X_train.size(1)\n",
        "    D_out = y_train.size(1)\n",
        "\n",
        "    epochs = 400\n",
        "    batch_size = 100\n",
        "    H = 100\n",
        "    net = Linear(D_in, H, D_out)\n",
        "\n",
        "    lr = 1e-4    \n",
        "    criterion = torch.nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        preds, epoch_loss, epoch_acc = train(net, criterion, optimizer, X_train, y_train, batch_size, n_classes)     \n",
        "        if (epoch % 50 == 0):\n",
        "            print(\"> epoch {:.0f}\\tLoss {:.5f}\\tAcc {:.5f}\".format(epoch, epoch_loss, epoch_acc))\n",
        "\n",
        "    net.eval()\n",
        "    \n",
        "    return net"
      ],
      "metadata": {
        "id": "NMIpvAyfDlFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_adv(config, method):\n",
        "    df_test = config['TestData']\n",
        "    extra_cols = ['orig_pred', 'adv_pred', 'iters']    \n",
        "    model = config['Model']\n",
        "    weights = config['Weights']\n",
        "    bounds = config['Bounds']\n",
        "    maxiters = config['MaxIters']\n",
        "    alpha = config['Alpha']\n",
        "    lambda_ = config['Lambda']\n",
        "    \n",
        "    results = np.zeros((len(df_test), len(feature_names) + len(extra_cols)))    \n",
        "            \n",
        "    i = -1\n",
        "    for _, row in tqdm_notebook(df_test.iterrows(), total=df_test.shape[0], desc=\"{}\".format(method)):\n",
        "        i += 1\n",
        "        x_tensor = torch.FloatTensor(row[config['FeatureNames']])   \n",
        "        \n",
        "        if method == 'LowProFool':\n",
        "            orig_pred, adv_pred, x_adv, loop_i = lowProFool(x_tensor, model, weights, bounds,\n",
        "                                                             maxiters, alpha, lambda_)\n",
        "            if(i==1):\n",
        "              print(x_tensor, x_adv)\n",
        "\n",
        "        elif method == 'Deepfool':\n",
        "            orig_pred, adv_pred, x_adv, loop_i = deepfool(x_tensor, model, maxiters, alpha,\n",
        "                                                          bounds, weights=[])\n",
        "        else:\n",
        "            raise Exception(\"Invalid method\", method)\n",
        "        results[i] = np.concatenate((x_adv, [orig_pred, adv_pred, loop_i]), axis=0)\n",
        "        \n",
        "    return pd.DataFrame(results, index=df_test.index, columns = feature_names + extra_cols)"
      ],
      "metadata": {
        "id": "fvUWRAksDn-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load initial dataset\n",
        "df_orig, target, feature_names = get_df2(DATASET)\n",
        "print(df_orig.columns)\n",
        "\n",
        "# Balance dataset classes\n",
        "df = balance_df(df_orig)\n",
        "\n",
        "# Compute the bounds for clipping\n",
        "bounds = get_bounds()\n",
        "\n",
        "# Normalize the data\n",
        "scaler, df, bounds = normalize(df, target, feature_names, bounds)\n",
        "\n",
        "# Compute the weihts modelizing the expert's knowledge\n",
        "weights = get_weights(df, target)\n",
        "\n",
        "# Split df into train/test/valid\n",
        "splits=int(df.shape[0]*0.2)\n",
        "df_train, df_test, df_valid = split_train_test_valid(int(splits/2),splits)\n",
        "\n",
        "# Build experimenation config\n",
        "config = {'Dataset'     : 'credit-g',\n",
        "         'MaxIters'     : 20000,\n",
        "         'Alpha'        : 0.001,\n",
        "         'Lambda'       : 8.5,\n",
        "         'TrainData'    : df_train,\n",
        "         'TestData'     : df_test,\n",
        "         'ValidData'    : df_valid,\n",
        "         'Scaler'       : scaler,\n",
        "         'FeatureNames' : feature_names,\n",
        "         'Target'       : target,\n",
        "         'Weights'      : weights,\n",
        "         'Bounds'       : bounds}\n",
        "\n",
        "# Train neural network\n",
        "model = get_model(config)\n",
        "config['Model'] = model\n",
        "\n",
        "# Compute accuracy on test set\n",
        "y_true = df_test[target]\n",
        "x_test = torch.FloatTensor(df_test[feature_names].values)\n",
        "y_pred = model(x_test)\n",
        "y_pred = np.argmax(y_pred.detach().numpy(), axis=1)\n",
        "print(\"Accuracy score on test data\", accuracy_score(y_true, y_pred))\n",
        "    \n",
        "# Sub sample\n",
        "config['TestData'] = config['TestData'].sample(n=150, random_state = SEED)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anbX5awuDxUO",
        "outputId": "778efffe-3a7b-4308-95c2-7915a34a5168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['availableMoney', 'transactionAmount', 'posEntryMode',\n",
            "       'posConditionCode', 'merchantCategoryCode', 'transactionType',\n",
            "       'currentBalance', 'cardPresent', 'expirationDateKeyInMatch',\n",
            "       'transactionDateTime_month', 'transactionDateTime_hour', 'isCVVcorrect',\n",
            "       'isSameCountry', 'isFraud'],\n",
            "      dtype='object')\n",
            "(24834, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> epoch 0\tLoss 0.02302\tAcc 0.57786\n",
            "> epoch 50\tLoss 0.02274\tAcc 0.64511\n",
            "> epoch 100\tLoss 0.02269\tAcc 0.65538\n",
            "> epoch 150\tLoss 0.02263\tAcc 0.66479\n",
            "> epoch 200\tLoss 0.02259\tAcc 0.66997\n",
            "> epoch 250\tLoss 0.02256\tAcc 0.67334\n",
            "> epoch 300\tLoss 0.02254\tAcc 0.67782\n",
            "> epoch 350\tLoss 0.02252\tAcc 0.68089\n",
            "Accuracy score on test data 0.6306886830447039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_adv2(config, method, cat_indices,max_vals,is_editable):\n",
        "    df_test = config['TestData']\n",
        "    extra_cols = ['orig_pred', 'adv_pred', 'iters']    \n",
        "    model = config['Model']\n",
        "    weights = config['Weights']\n",
        "    bounds = config['Bounds']\n",
        "    maxiters = config['MaxIters']\n",
        "    alpha = config['Alpha']\n",
        "    lambda_ = config['Lambda']\n",
        "    \n",
        "    results = np.zeros((len(df_test), len(feature_names) + len(extra_cols)))    \n",
        "            \n",
        "    i = -1\n",
        "    for _, row in tqdm_notebook(df_test.iterrows(), total=df_test.shape[0], desc=\"{}\".format(method)):\n",
        "        i += 1\n",
        "        x_tensor = torch.FloatTensor(row[config['FeatureNames']])   \n",
        "        \n",
        "        if method == 'LowProFool':\n",
        "            orig_pred, adv_pred, x_adv, loop_i = lowProFool2(x_tensor, model, weights, bounds,\n",
        "                                                             maxiters, alpha, lambda_,\n",
        "                                                             cat_indices,max_vals,is_editable)\n",
        "            if(i==1):\n",
        "              print(x_tensor, x_adv)\n",
        "\n",
        "        elif method == 'Deepfool':\n",
        "            orig_pred, adv_pred, x_adv, loop_i = deepfool(x_tensor, model, maxiters, alpha,\n",
        "                                                          bounds, weights=[])\n",
        "        else:\n",
        "            raise Exception(\"Invalid method\", method)\n",
        "        results[i] = np.concatenate((x_adv, [orig_pred, adv_pred, loop_i]), axis=0)\n",
        "        \n",
        "    return pd.DataFrame(results, index=df_test.index, columns = feature_names + extra_cols)\n",
        "\n",
        "def lowProFool2(x, model, weights, bounds, maxiters, alpha, lambda_, cat_indices,max_vals, is_editable):\n",
        "    \"\"\"\n",
        "    Generates an adversarial examples x' from an original sample x\n",
        "\n",
        "    :param x: tabular sample\n",
        "    :param model: neural network\n",
        "    :param weights: feature importance vector associated with the dataset at hand\n",
        "    :param bounds: bounds of the datasets with respect to each feature\n",
        "    :param maxiters: maximum number of iterations ran to generate the adversarial examples\n",
        "    :param alpha: scaling factor used to control the growth of the perturbation\n",
        "    :param lambda_: trade off factor between fooling the classifier and generating imperceptible adversarial example\n",
        "    :return: original label prediction, final label prediction, adversarial examples x', iteration at which the class changed\n",
        "    \"\"\"\n",
        "\n",
        "    r = Variable(torch.FloatTensor(1e-8 * np.ones(x.numpy().shape)), requires_grad=True) \n",
        "    v = torch.FloatTensor(np.array(weights))\n",
        "    num_idx = cat_indices\n",
        "    n_print_samples=5\n",
        "    n_print_counter=0\n",
        "    \n",
        "    output = model.forward(x + r)\n",
        "    orig_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "    target_pred = np.abs(1 - orig_pred)\n",
        "    \n",
        "    target = [0., 1.] if target_pred == 1 else [1., 0.]\n",
        "    target = Variable(torch.tensor(target, requires_grad=False)) \n",
        "    \n",
        "    lambda_ = torch.tensor([lambda_])\n",
        "    \n",
        "    bce = nn.BCELoss()\n",
        "    l1 = lambda v, r: torch.sum(torch.abs(v * r)) #L1 norm\n",
        "    l2 = lambda v, r: torch.sqrt(torch.sum(torch.mul(v * r,v * r))) #L2 norm\n",
        "    \n",
        "    best_norm_weighted = np.inf\n",
        "    best_pert_x = x\n",
        "    \n",
        "    loop_i, loop_change_class = 0, 0\n",
        "    while loop_i < maxiters:\n",
        "            \n",
        "        zero_gradients(r)\n",
        "\n",
        "        # Computing loss \n",
        "        loss_1 = bce(output, target)\n",
        "        loss_2 = l2(v, r)\n",
        "        loss = (loss_1 + lambda_ * loss_2)\n",
        "\n",
        "        # Get the gradient\n",
        "        loss.backward(retain_graph=True)\n",
        "        grad_r = r.grad.data.cpu().numpy().copy()\n",
        "        \n",
        "        # Guide perturbation to the negative of the gradient\n",
        "        ri = - grad_r\n",
        "    \n",
        "        # limit huge step\n",
        "        ri *= alpha\n",
        "\n",
        "        # Adds new perturbation to total perturbation\n",
        "        r = r.clone().detach().cpu().numpy() + ri\n",
        "        \n",
        "        # For later computation\n",
        "        r_norm_weighted = np.sum(np.abs(r * weights))\n",
        "        \n",
        "        # Ready to feed the model\n",
        "        r = Variable(torch.FloatTensor(r), requires_grad=True) \n",
        "        \n",
        "        # Compute adversarial example\n",
        "        xprime = x + r\n",
        "        \n",
        "        # Clip to stay in legitimate bounds\n",
        "        xprime = clip(xprime, bounds[0], bounds[1])\n",
        "        # print(xprime)\n",
        "        # gfun = xprime.grad_fn\n",
        "        \n",
        "        counter = 0\n",
        "\n",
        "        # if n_print_counter<n_print_samples:\n",
        "        #     print(\"before mod\")\n",
        "        #     print(xprime,x)\n",
        "\n",
        "        for cat_idx, bnd, editable in zip( cat_indices, max_vals, is_editable):\n",
        "          # print(x.item())\n",
        "          # print(bnd)\n",
        "          if editable:\n",
        "            if cat_idx:\n",
        "              if xprime[counter].item()==0:\n",
        "                xprime[counter] = 0\n",
        "              else:\n",
        "\n",
        "                # if n_print_counter<n_print_samples:\n",
        "                #   print(counter, float(round(xprime[counter].item()*bnd)/bnd))\n",
        "\n",
        "                xprime[counter] = math.tanh(xprime[counter].item()*bnd)/bnd\n",
        "          else:\n",
        "            xprime[counter]  = x[counter]\n",
        "          counter += 1\n",
        "          # print(counter)\n",
        "          # print(xprime)\n",
        "\n",
        "        # if n_print_counter<n_print_samples:\n",
        "        #   print(\"after mod\")\n",
        "        #   print(xprime)\n",
        "        #   n_print_counter+=1\n",
        "            \n",
        "\n",
        "        \n",
        "        # print(xprime)\n",
        "        \n",
        "        # Classify adversarial example\n",
        "        output = model.forward(xprime)\n",
        "        output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "        \n",
        "        # Keep the best adverse at each iterations\n",
        "        if output_pred != orig_pred and r_norm_weighted < best_norm_weighted:\n",
        "            best_norm_weighted = r_norm_weighted\n",
        "            best_pert_x = xprime\n",
        "\n",
        "        if output_pred == orig_pred:\n",
        "            loop_change_class += 1\n",
        "            \n",
        "        loop_i += 1 \n",
        "        \n",
        "    # Clip at the end no matter what\n",
        "    best_pert_x = clip(best_pert_x, bounds[0], bounds[1])\n",
        "    output = model.forward(best_pert_x)\n",
        "    output_pred = output.max(0, keepdim=True)[1].cpu().numpy()\n",
        "\n",
        "    return orig_pred, output_pred, best_pert_x.clone().detach().cpu().numpy(), loop_change_class \n"
      ],
      "metadata": {
        "id": "qPVIcYszDx2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "config2 = deepcopy(config)\n",
        "config2['TestData'] = config2['TestData'].sample(n=150, random_state = SEED)\n",
        "max_vals = df_orig.max().astype(float).tolist()[:-1]\n",
        "is_editable = [False, True, False, False, True, False, False, False, False, True, True, True , True]\n",
        "\n",
        "lpf_test = gen_adv2(config2,\"LowProFool\",\n",
        "                    cat_indices=[False, False, True, True, True, True, False, True, True, True, True, True, True],\n",
        "                    max_vals=max_vals, is_editable=is_editable )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "f88c7cca31f64a69ae62f23cdf908f2c",
            "37fdebabea334e8bbc2ff0b9ee0b2bc8",
            "222782b3bf4f403cb316fc14e2a3fa98",
            "0a5d831869a3460681e9c97c0a8953d0",
            "c34d2786acf449a09bf8ad2323c1ec2b",
            "0417910abfda4caea4e1c3a5a4e384ae",
            "8db21f0ac1b34079a066546b7f8278d8",
            "39ffc1ab7595471c8d3b5cbda9766c80",
            "06245990d1e94ff6868e6f4b0c594a36",
            "5fda2f208c4540e486cf97efa2c8bf12",
            "c2faebb0d60d4aa2aa88897770819780"
          ]
        },
        "id": "fqzyxIKLEun5",
        "outputId": "602e928b-fb81-48ec-fbc4-132b1972c71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-d5a17e28e6bc>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for _, row in tqdm_notebook(df_test.iterrows(), total=df_test.shape[0], desc=\"{}\".format(method)):\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f88c7cca31f64a69ae62f23cdf908f2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "LowProFool:   0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8284, 0.0199, 0.4000, 0.0000, 0.7222, 0.3333, 0.1716, 0.0000, 0.0000,\n",
            "        0.1818, 0.2174, 1.0000, 1.0000]) [0.82844895 0.01988091 0.4        0.         0.7222222  0.33333334\n",
            " 0.17155103 0.         0.         0.18181819 0.2173913  1.\n",
            " 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['posEntryMode'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoaXuspXQT6E",
        "outputId": "f0806d80-32b6-4206-a83d-9153cc38a713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4    907\n",
              "0.2    771\n",
              "0.0    651\n",
              "0.8     65\n",
              "0.6     60\n",
              "1.0     29\n",
              "Name: posEntryMode, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['posEntryMode'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e-T5aXmQaNq",
        "outputId": "bd78d7a4-e743-4a7f-b3f5-23db15f0f11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4    58\n",
              "0.2    41\n",
              "0.0    40\n",
              "0.6     6\n",
              "0.8     3\n",
              "1.0     2\n",
              "Name: posEntryMode, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['posConditionCode'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6gcKlsxQeNq",
        "outputId": "ef6d2634-1ea8-4fd2-a9b9-3819776c2f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.66666669, 0.33333334])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['posConditionCode'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ3jjknaQhgV",
        "outputId": "ce3044d0-beda-4692-e48d-70ba015f1f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000000    1987\n",
              "0.333333     454\n",
              "0.666667      39\n",
              "1.000000       3\n",
              "Name: posConditionCode, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['cardPresent'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkFBkvVTQlUF",
        "outputId": "92464925-8584-49bb-d891-759cc6414bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['cardPresent'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qSPW05kQn_8",
        "outputId": "ef4a0b77-efdc-4f86-95e1-b9d1c28fe4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['isCVVcorrect'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xrCRc2-Qqjx",
        "outputId": "2edafaea-0855-4eee-858c-11f3cc0086e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.76154202, 1.        , 0.76141882, 0.76159418, 0.76058632,\n",
              "       0.76157004, 0.76109624, 0.76154011, 0.76159114, 0.76154959,\n",
              "       0.76152724, 0.76148194, 0.76104313, 0.76158106, 0.76116008,\n",
              "       0.76143599, 0.76159412, 0.76153433, 0.        , 0.76158261,\n",
              "       0.76114553, 0.76122779, 0.76159269, 0.7603125 , 0.76159203])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['isCVVcorrect'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ho0retxQvH9",
        "outputId": "b0b15dc7-4dc7-4b1b-a3af-e0687e484153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['isSameCountry'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J4IuuMyQyg2",
        "outputId": "66cf3764-2e0c-4028-e423-e5e7379661f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['expirationDateKeyInMatch'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbruEDMtRB_v",
        "outputId": "c89f8406-04c8-4368-8599-4bc4cb17ddda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['expirationDateKeyInMatch'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEFuYiR_RFNt",
        "outputId": "03ed96af-adca-4de1-e2c2-784636168679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['isSameCountry'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJZrWe9tQ05d",
        "outputId": "b654354e-2a10-46a1-c50b-6a836be2f7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.76159412, 1.        , 0.76159418, 0.76117724, 0.76159173,\n",
              "       0.76022083, 0.75997502, 0.7607553 , 0.76159328, 0.761594  ,\n",
              "       0.76107931, 0.7615726 , 0.76144642, 0.76159132, 0.76158315,\n",
              "       0.76094645, 0.76046586, 0.76159394, 0.76147562, 0.76155835,\n",
              "       0.76134163, 0.76049805, 0.76159221, 0.76105225, 0.76028806,\n",
              "       0.76037699, 0.76158816])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "FW5DOy3bRibO",
        "outputId": "86cfcf1d-a10f-4c6a-c6f8-3eb6cf9af2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        availableMoney  transactionAmount  posEntryMode  posConditionCode  \\\n",
              "247099        0.946840           0.002966           0.6          0.000000   \n",
              "160382        0.828449           0.019881           0.4          0.000000   \n",
              "488118        0.994751           0.007530           0.4          0.000000   \n",
              "89712         0.746087           0.006713           0.0          0.000000   \n",
              "600905        0.792597           0.053297           0.4          0.000000   \n",
              "...                ...                ...           ...               ...   \n",
              "394519        0.797239           0.002927           0.4          0.000000   \n",
              "293147        0.993552           0.006237           0.4          0.000000   \n",
              "353098        1.000000           0.108476           0.0          0.333333   \n",
              "396136        0.906530           0.018406           0.2          0.000000   \n",
              "714288        0.741323           0.006662           0.4          0.000000   \n",
              "\n",
              "        merchantCategoryCode  transactionType  currentBalance  cardPresent  \\\n",
              "247099              0.055556         0.333333        0.053160          0.0   \n",
              "160382              0.722222         0.333333        0.171551          0.0   \n",
              "488118              0.055555         0.333333        0.005249          0.0   \n",
              "89712               0.777778         0.333333        0.253913          0.0   \n",
              "600905              0.055281         0.333333        0.207403          1.0   \n",
              "...                      ...              ...             ...          ...   \n",
              "394519              0.777778         0.333333        0.202761          0.0   \n",
              "293147              1.000000         0.333333        0.006448          0.0   \n",
              "353098              0.555556         0.333333        0.000000          0.0   \n",
              "396136              0.055518         0.333333        0.093470          0.0   \n",
              "714288              0.944444         0.333333        0.258677          0.0   \n",
              "\n",
              "        expirationDateKeyInMatch  transactionDateTime_month  \\\n",
              "247099                       0.0                   0.081239   \n",
              "160382                       0.0                   0.181818   \n",
              "488118                       0.0                   0.000000   \n",
              "89712                        0.0                   0.909091   \n",
              "600905                       0.0                   0.083330   \n",
              "...                          ...                        ...   \n",
              "394519                       0.0                   0.363636   \n",
              "293147                       0.0                   0.000000   \n",
              "353098                       0.0                   0.909091   \n",
              "396136                       0.0                   0.083333   \n",
              "714288                       0.0                   0.181818   \n",
              "\n",
              "        transactionDateTime_hour  isCVVcorrect  isSameCountry  orig_pred  \\\n",
              "247099                  0.033967      0.761542       0.761594        0.0   \n",
              "160382                  0.217391      1.000000       1.000000        1.0   \n",
              "488118                  0.043478      0.761419       0.761594        0.0   \n",
              "89712                   0.956522      1.000000       1.000000        1.0   \n",
              "600905                  0.043478      0.761594       0.761594        0.0   \n",
              "...                          ...           ...            ...        ...   \n",
              "394519                  0.173913      1.000000       1.000000        1.0   \n",
              "293147                  0.695652      1.000000       1.000000        1.0   \n",
              "353098                  0.347826      1.000000       1.000000        1.0   \n",
              "396136                  0.043478      0.761594       0.761594        0.0   \n",
              "714288                  0.173913      1.000000       1.000000        1.0   \n",
              "\n",
              "        adv_pred    iters  \n",
              "247099       1.0      0.0  \n",
              "160382       1.0  20000.0  \n",
              "488118       1.0      0.0  \n",
              "89712        1.0  20000.0  \n",
              "600905       1.0      0.0  \n",
              "...          ...      ...  \n",
              "394519       1.0  20000.0  \n",
              "293147       1.0  20000.0  \n",
              "353098       1.0  20000.0  \n",
              "396136       1.0      0.0  \n",
              "714288       1.0  20000.0  \n",
              "\n",
              "[150 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93cc5c0e-7554-4f68-9cd0-0174aa109f69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>availableMoney</th>\n",
              "      <th>transactionAmount</th>\n",
              "      <th>posEntryMode</th>\n",
              "      <th>posConditionCode</th>\n",
              "      <th>merchantCategoryCode</th>\n",
              "      <th>transactionType</th>\n",
              "      <th>currentBalance</th>\n",
              "      <th>cardPresent</th>\n",
              "      <th>expirationDateKeyInMatch</th>\n",
              "      <th>transactionDateTime_month</th>\n",
              "      <th>transactionDateTime_hour</th>\n",
              "      <th>isCVVcorrect</th>\n",
              "      <th>isSameCountry</th>\n",
              "      <th>orig_pred</th>\n",
              "      <th>adv_pred</th>\n",
              "      <th>iters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>247099</th>\n",
              "      <td>0.946840</td>\n",
              "      <td>0.002966</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.053160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.081239</td>\n",
              "      <td>0.033967</td>\n",
              "      <td>0.761542</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160382</th>\n",
              "      <td>0.828449</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.171551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488118</th>\n",
              "      <td>0.994751</td>\n",
              "      <td>0.007530</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055555</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.761419</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89712</th>\n",
              "      <td>0.746087</td>\n",
              "      <td>0.006713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.253913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600905</th>\n",
              "      <td>0.792597</td>\n",
              "      <td>0.053297</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055281</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.207403</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083330</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394519</th>\n",
              "      <td>0.797239</td>\n",
              "      <td>0.002927</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.202761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293147</th>\n",
              "      <td>0.993552</td>\n",
              "      <td>0.006237</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.006448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353098</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.108476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396136</th>\n",
              "      <td>0.906530</td>\n",
              "      <td>0.018406</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055518</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.093470</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714288</th>\n",
              "      <td>0.741323</td>\n",
              "      <td>0.006662</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.258677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93cc5c0e-7554-4f68-9cd0-0174aa109f69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93cc5c0e-7554-4f68-9cd0-0174aa109f69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93cc5c0e-7554-4f68-9cd0-0174aa109f69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['adv_pred'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsQRVBIcR4IA",
        "outputId": "cfe3784f-ddb6-42ae-fdab-3bc0905481a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    130\n",
              "0.0     20\n",
              "Name: adv_pred, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test['orig_pred'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bghdldvySaYL",
        "outputId": "b4cff250-04cd-4399-bffb-0b7de1b1ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    94\n",
              "1.0    56\n",
              "Name: orig_pred, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lpf_test.query(\"iters>0 and iters<20000 and orig_pred==1 and adv_pred==0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "S5CXTBxRSrlR",
        "outputId": "de98d707-2afe-4939-e1c9-4ff253beec34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        availableMoney  transactionAmount  posEntryMode  posConditionCode  \\\n",
              "161502        0.751706           0.000536           0.4               0.0   \n",
              "201022        0.878488           0.001023           0.2               0.0   \n",
              "\n",
              "        merchantCategoryCode  transactionType  currentBalance  cardPresent  \\\n",
              "161502              0.042311         0.333333        0.248294          1.0   \n",
              "201022              0.055556         0.333333        0.121512          0.0   \n",
              "\n",
              "        expirationDateKeyInMatch  transactionDateTime_month  \\\n",
              "161502                       0.0                   0.083333   \n",
              "201022                       0.0                   0.083333   \n",
              "\n",
              "        transactionDateTime_hour  isCVVcorrect  isSameCountry  orig_pred  \\\n",
              "161502                  0.043478      0.761594       0.761594        1.0   \n",
              "201022                  0.043478      0.761594       0.761594        1.0   \n",
              "\n",
              "        adv_pred  iters  \n",
              "161502       0.0    2.0  \n",
              "201022       0.0    1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7059ac9-fd0f-4a46-ad54-a1c4afac9468\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>availableMoney</th>\n",
              "      <th>transactionAmount</th>\n",
              "      <th>posEntryMode</th>\n",
              "      <th>posConditionCode</th>\n",
              "      <th>merchantCategoryCode</th>\n",
              "      <th>transactionType</th>\n",
              "      <th>currentBalance</th>\n",
              "      <th>cardPresent</th>\n",
              "      <th>expirationDateKeyInMatch</th>\n",
              "      <th>transactionDateTime_month</th>\n",
              "      <th>transactionDateTime_hour</th>\n",
              "      <th>isCVVcorrect</th>\n",
              "      <th>isSameCountry</th>\n",
              "      <th>orig_pred</th>\n",
              "      <th>adv_pred</th>\n",
              "      <th>iters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161502</th>\n",
              "      <td>0.751706</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042311</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.248294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201022</th>\n",
              "      <td>0.878488</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.121512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7059ac9-fd0f-4a46-ad54-a1c4afac9468')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7059ac9-fd0f-4a46-ad54-a1c4afac9468 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7059ac9-fd0f-4a46-ad54-a1c4afac9468');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yf6qO6q6S16M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}